{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe50a74",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dba7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "importances = None\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data=pd.read_csv('ECommerceDataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e549db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b69f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking shape and size of dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccb28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=data.shape\n",
    "size=data.size\n",
    "print(shape)\n",
    "print(size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d37a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the missing percentage of data for this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a95dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingvalpercentage=(data.isnull().sum()/len(data))*100\n",
    "print(missingvalpercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd979e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As there is need to maintain integrity of data we will do data imputation for missing valuse instead of data removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tenure'] = data['Tenure'].fillna(data['Tenure'].median())\n",
    "data['WarehouseToHome'] = data['WarehouseToHome'].fillna(data['WarehouseToHome'].median())\n",
    "data['HourSpendOnApp'] = data['HourSpendOnApp'].fillna(data['HourSpendOnApp'].median())\n",
    "data['OrderAmountHikeFromlastYear'] = data['OrderAmountHikeFromlastYear'].fillna(data['OrderAmountHikeFromlastYear'].median())\n",
    "data['CouponUsed'] = data['CouponUsed'].fillna(data['CouponUsed'].median())\n",
    "data['OrderCount'] = data['OrderCount'].fillna(data['OrderCount'].median())\n",
    "data['DaySinceLastOrder'] = data['DaySinceLastOrder'].fillna(data['DaySinceLastOrder'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkinng whether the imputation is done or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81bd340",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa1cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lets have a descriptive info of data \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e857af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets have basic information about data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c7a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#having a look at datahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a9e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86b946",
   "metadata": {},
   "source": [
    "### feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ab758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will do one hot encoding for nominal features of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataencoded=pd.get_dummies(data,columns=['PreferredLoginDevice','PreferredPaymentMode','Gender','PreferedOrderCat','MaritalStatus'])\n",
    "dataencoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4435e514",
   "metadata": {},
   "source": [
    "###### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a498f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerical_columns=data.select_dtypes(include=['float64','int64']).columns\n",
    "scaler=StandardScaler()\n",
    "data[numerical_columns]=scaler.fit_transform(data[numerical_columns])\n",
    "print(tabulate(data.head(), headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25cdd86",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=data, x='Churn', hue='Churn', palette='viridis', dodge=False, legend=False)\n",
    "plt.title('Churn Distribution')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37500a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(data=data, y='OrderAmountHikeFromlastYear')\n",
    "plt.title('Distribution of Order Amount Hike from Last Year')\n",
    "plt.ylabel('Order Amount Hike (%)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(data['HourSpendOnApp'], bins=20, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of Hour Spend on App')\n",
    "plt.xlabel('Hours Spent on App')\n",
    "plt.ylabel('Number of Customers')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec080cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=data, x='NumberOfDeviceRegistered', kde=True)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of Number of Devices Registered')\n",
    "plt.xlabel('Number of Devices Registered')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3991f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data, x='Churn', y='SatisfactionScore')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Satisfaction Score by Churn Status')\n",
    "plt.xlabel('Churn (0 = Retained, 1 = Churned)')\n",
    "plt.ylabel('Satisfaction Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb20f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=data, x='Churn', y='HourSpendOnApp', estimator='mean')\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title('Average Hour Spend on App by Churn Status')\n",
    "plt.xlabel('Churn (0=retained, 1=churned)')\n",
    "plt.ylabel('Average Hour Spend on App')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=data, x='Churn', y='NumberOfDeviceRegistered', estimator='mean')\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title('Average Number of Devices Registered by Churn Status')\n",
    "plt.xlabel('Churn (0=retained, 1=churned)')\n",
    "plt.ylabel('Average Number of Devices Registered')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=data, x='NumberOfAddress', bins=20, kde=True)\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title('Distribution of Number of Addresses')\n",
    "plt.xlabel('Number of Addresses')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=data, x='Churn', y='CashbackAmount', errorbar=None)\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title('Average Cashback Amount by Churn Status')\n",
    "plt.xlabel('Churn (0 = Retained, 1 = Churned)')\n",
    "plt.ylabel('Average Cashback Amount')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data, x='CityTier', y='SatisfactionScore')\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title('Distribution of Satisfaction Score by City Tier')\n",
    "plt.xlabel('City Tier')\n",
    "plt.ylabel('Satisfaction Score')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227ecff4",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac004ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'Tenure': [1, 7, 13, 25, 37, 50, 68, 72],  # Example data\n",
    "    'HourSpendOnApp': [1.5, 2.0, 1.2, 2.5, 3.0, 2.0, 1.8, 2.2],  # Example data\n",
    "    'OrderCount': [5, 8, 3, 6, 7, 4, 9, 5]  # Example data\n",
    "})\n",
    "\n",
    "# Define bins and labels\n",
    "bins = [0, 6, 12, 24, 36, 48, 60, 72]\n",
    "labels = ['0-6 months', '6-12 months', '1-2 years', '2-3 years', '3-4 years', '4-5 years', '5-6 years']\n",
    "\n",
    "# Create tenure category column\n",
    "data['TenureCategory'] = pd.cut(data['Tenure'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Create interaction term\n",
    "data['Interaction'] = data['HourSpendOnApp'] * data['OrderCount']\n",
    "\n",
    "# Create average hours per order column\n",
    "data['AvgHoursPerOrder'] = data['HourSpendOnApp'] / (data['OrderCount'] + 1)\n",
    "\n",
    "# Display the dataframe with the new columns\n",
    "print(data[['Tenure', 'TenureCategory', 'HourSpendOnApp', 'OrderCount', 'Interaction', 'AvgHoursPerOrder']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c99fe",
   "metadata": {},
   "source": [
    "# Feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('ECommerceDataset.csv')\n",
    "\n",
    "# Check the column names and data types\n",
    "print(\"Column Names and Data Types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Check if 'Churn' exists and convert if needed\n",
    "if 'Churn' in data.columns:\n",
    "    if data['Churn'].dtype not in ['float64', 'int64']:\n",
    "        data['Churn'] = pd.to_numeric(data['Churn'], errors='coerce')\n",
    "else:\n",
    "    raise ValueError(\"Column 'Churn' is missing from the dataframe.\")\n",
    "\n",
    "# Define bins and labels for TenureCategory if needed\n",
    "bins = [0, 6, 12, 24, 36, 48, 60, 72]\n",
    "labels = ['0-6 months', '6-12 months', '1-2 years', '2-3 years', '3-4 years', '4-5 years', '5-6 years']\n",
    "\n",
    "# Create tenure category column if not already present\n",
    "if 'TenureCategory' not in data.columns:\n",
    "    data['TenureCategory'] = pd.cut(data['Tenure'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Create interaction term if not already present\n",
    "if 'Interaction' not in data.columns:\n",
    "    data['Interaction'] = data['HourSpendOnApp'] * data['OrderCount']\n",
    "\n",
    "# Create average hours per order column if not already present\n",
    "if 'AvgHoursPerOrder' not in data.columns:\n",
    "    data['AvgHoursPerOrder'] = data['HourSpendOnApp'] / (data['OrderCount'] + 1)\n",
    "\n",
    "# Select only numeric columns for correlation matrix\n",
    "numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Check if 'Churn' is present in the numeric columns\n",
    "if 'Churn' not in numeric_data.columns:\n",
    "    print(\"The 'Churn' column is not present in the numeric columns for correlation.\")\n",
    "else:\n",
    "    # Compute the correlation matrix\n",
    "    correlation_matrix = numeric_data.corr()\n",
    "\n",
    "    # Generate a heatmap for the correlation matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # Display correlation of features with the target variable 'Churn'\n",
    "    print(\"Correlation of features with 'Churn':\")\n",
    "    print(correlation_matrix['Churn'].sort_values(ascending=False))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec8c50",
   "metadata": {},
   "source": [
    "# Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric features to be standardized\n",
    "numeric_features = ['Tenure', 'HourSpendOnApp', 'OrderCount', 'WarehouseToHome',\n",
    "                     'SatisfactionScore', 'NumberOfDeviceRegistered', 'NumberOfAddress',\n",
    "                     'OrderAmountHikeFromlastYear', 'CouponUsed', 'DaySinceLastOrder',\n",
    "                     'CashbackAmount', 'Interaction', 'AvgHoursPerOrder']\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numeric features\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])\n",
    "\n",
    "# Verify the transformation\n",
    "print(data[numeric_features].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in each column:\")\n",
    "print(data[numeric_features].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with the median\n",
    "data[numeric_features] = data[numeric_features].fillna(data[numeric_features].median())\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "print(\"Missing values after imputation:\")\n",
    "print(data[numeric_features].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[numeric_features].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ab917",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ECommerceDataset.csv')\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(columns=['Churn'])\n",
    "y = data['Churn']\n",
    "\n",
    "# Identify categorical features\n",
    "categorical_features = ['PreferredLoginDevice', 'PreferredPaymentMode', 'Gender', 'PreferedOrderCat', 'MaritalStatus']\n",
    "\n",
    "# Create a column transformer for encoding categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the numeric features unchanged\n",
    ")\n",
    "\n",
    "# Transform the data\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X_transformed)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_imputed, y)\n",
    "rf_importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for Random Forest feature importances\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    'Feature': preprocessor.get_feature_names_out(),\n",
    "    'Importance': rf_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot Random Forest Feature Importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=rf_importance_df)\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# Train Lasso model\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_imputed, y)\n",
    "lasso_coefficients = lasso.coef_\n",
    "\n",
    "# Create a DataFrame for Lasso coefficients\n",
    "lasso_importance_df = pd.DataFrame({\n",
    "    'Feature': preprocessor.get_feature_names_out(),\n",
    "    'Coefficient': lasso_coefficients\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Plot Lasso Feature Coefficients\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=lasso_importance_df)\n",
    "plt.title('Feature Importance from Lasso Regression')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('ECommerceDataset.csv')\n",
    "\n",
    "# Check the column names and data types\n",
    "print(\"Column Names and Data Types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Check if 'Churn' exists and convert if needed\n",
    "if 'Churn' in data.columns:\n",
    "    if data['Churn'].dtype not in ['float64', 'int64']:\n",
    "        data['Churn'] = pd.to_numeric(data['Churn'], errors='coerce')\n",
    "else:\n",
    "    raise ValueError(\"Column 'Churn' is missing from the dataframe.\")\n",
    "\n",
    "# Define bins and labels for TenureCategory if needed\n",
    "bins = [0, 6, 12, 24, 36, 48, 60, 72]\n",
    "labels = ['0-6 months', '6-12 months', '1-2 years', '2-3 years', '3-4 years', '4-5 years', '5-6 years']\n",
    "\n",
    "# Create tenure category column if not already present\n",
    "if 'TenureCategory' not in data.columns:\n",
    "    data['TenureCategory'] = pd.cut(data['Tenure'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Create interaction term if not already present\n",
    "if 'Interaction' not in data.columns:\n",
    "    data['Interaction'] = data['HourSpendOnApp'] * data['OrderCount']\n",
    "\n",
    "# Create average hours per order column if not already present\n",
    "if 'AvgHoursPerOrder' not in data.columns:\n",
    "    data['AvgHoursPerOrder'] = data['HourSpendOnApp'] / (data['OrderCount'] + 1)\n",
    "\n",
    "# Verify column names\n",
    "print(\"Available columns in data:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Verify creation of necessary columns\n",
    "missing_features = []\n",
    "if 'Interaction' not in data.columns:\n",
    "    missing_features.append(\"Interaction\")\n",
    "if 'AvgHoursPerOrder' not in data.columns:\n",
    "    missing_features.append(\"AvgHoursPerOrder\")\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"Missing columns: {', '.join(missing_features)}\")\n",
    "\n",
    "# Define selected features\n",
    "selected_features = [\n",
    "    'Tenure', 'HourSpendOnApp', 'OrderCount',\n",
    "    'WarehouseToHome', 'SatisfactionScore', 'NumberOfDeviceRegistered',\n",
    "    'NumberOfAddress', 'OrderAmountHikeFromlastYear', 'CouponUsed',\n",
    "    'DaySinceLastOrder', 'Interaction', 'AvgHoursPerOrder'\n",
    "]\n",
    "\n",
    "# Check if all selected features exist\n",
    "available_features = [feature for feature in selected_features if feature in data.columns]\n",
    "print(\"Features available for final DataFrame:\")\n",
    "print(available_features)\n",
    "\n",
    "# Prepare the final DataFrame\n",
    "final_data = data[available_features + ['Churn']]\n",
    "\n",
    "# Check for missing values and handle them\n",
    "print(\"Missing values in final data:\")\n",
    "print(final_data.isnull().sum())\n",
    "\n",
    "# Impute missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "final_data_imputed = pd.DataFrame(imputer.fit_transform(final_data), columns=final_data.columns)\n",
    "\n",
    "# Verify data after imputation\n",
    "print(\"Missing values after imputation:\")\n",
    "print(final_data_imputed.isnull().sum())\n",
    "\n",
    "# Split the data into features and target\n",
    "X = final_data_imputed.drop('Churn', axis=1)\n",
    "y = final_data_imputed['Churn']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print feature importances\n",
    "importances = clf.feature_importances_\n",
    "feature_importance = pd.DataFrame({'Feature': available_features, 'Importance': importances})\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance.sort_values(by='Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap lime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the SHAP explainer\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Print detailed shapes to debug\n",
    "print(\"Number of classes:\", len(shap_values))\n",
    "for i, values in enumerate(shap_values):\n",
    "    print(f\"SHAP values shape for class {i}: {values.shape}\")\n",
    "\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "\n",
    "# Ensure the dimensions match\n",
    "is_multiclass = len(shap_values) > 2\n",
    "\n",
    "if is_multiclass:\n",
    "    # For multi-class, check each class\n",
    "    for i in range(len(shap_values)):\n",
    "        print(f\"Class {i} SHAP values shape: {shap_values[i].shape}\")\n",
    "        if shap_values[i].shape[0] != X_test.shape[0]:\n",
    "            print(f\"Shape mismatch for class {i}:\")\n",
    "            print(f\"SHAP values shape: {shap_values[i].shape}\")\n",
    "            print(f\"Test data shape: {X_test.shape}\")\n",
    "        else:\n",
    "            print(f\"Class {i} SHAP values shape matches.\")\n",
    "else:\n",
    "    # For binary classification, check class 1\n",
    "    if shap_values[1].shape[0] != X_test.shape[0]:\n",
    "        print(f\"Shape mismatch for class 1:\")\n",
    "        print(f\"SHAP values shape: {shap_values[1].shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}\")\n",
    "    else:\n",
    "        print(\"SHAP values shape matches for class 1.\")\n",
    "\n",
    "# Convert X_test to DataFrame for better readability\n",
    "X_test_df = pd.DataFrame(X_test, columns=data.columns[2:])  # Adjust columns as needed\n",
    "\n",
    "# Print sample rows of X_test\n",
    "print(\"Sample rows of X_test:\")\n",
    "print(X_test_df.head())\n",
    "\n",
    "# Plot SHAP values\n",
    "if not is_multiclass:\n",
    "    shap.summary_plot(shap_values[1], X_test)\n",
    "else:\n",
    "    # Plot for each class if multi-class classification\n",
    "    for i in range(len(shap_values)):\n",
    "        print(f\"Plotting SHAP values for class {i}\")\n",
    "        shap.summary_plot(shap_values[i], X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f99e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
